\section{Optimization} \label{sec:implementation}
We employ \theoremref{Thm:supporting_plane} and its discretization eq.\eqref{eq:folding_const} in a simple algorithm to enforce folds along creases while deforming piecewise smooth DOGs. The algorithm tries to minimize an objective, while keeping the DOG constraints and ensuring the formation of folds along all crease curves.

\subsection{Problem setup}
We model our curved folded surfaces as a quad mesh, with a separate connected component for each patch. We denote the set of $n$ mesh vertices in $R^3$ by $V \in R^{n\times3}$, the flattened variables by $\x \in R^{3n}$, and the mesh quad faces by $F$. Each connected component by its own is a DOG, i.e. has the connectivity of a subset of $\Z^2$ and satisfy the DOG angle constraints \cite{rabi18}. The patches themselves also need to align along the crease as detailed at \ref{sec:model} enforced by simple linear constraints as done in \cite{rabi2018shape}. For convenience we call both of these constraints the "DOG constraints" and denote them by $\phi_{d_i}(\x) = 0, 1 \leq i \leq m$.

We are interested in deformations that fold along all creases in a given folding pattern using \theoremref{Thm:supporting_plane} and enforcing eq. \eqref{eq:folding_const} on all crease points, which are points on crease curves having two neighbours. Let $\phi_{f_i}(\x) = 0, 1 \leq i \leq k$ be the folding constraint \eqref{eq:folding_const} for the inner crease points, together with a few optional M/V assignment constraints \eqref{eq:mountain_valley}.

The problems we solve in this paper can be written in the form:
\begin{equation} \label{eq:const_opt}
\begin{aligned}
& \argmin_x f(x) \\
& \textrm{subject to} \\
& \phi_{d_i}(\x) = 0, \ \  i = 1, \ldots, m. \\
& \phi_{f_i}(\x) = 0, \ \  i = 1, \ldots, k \\ 
\end{aligned}
\end{equation}
With $f$ as an objective, composed of a weighted sum of a bending objective, isometry objective, positional constraints and other terms as specified in \secref{sec:dog_obj}.

\subsection{Folding constraints}
Motivated by the fact that in the smooth case one cannot move from a folded to a non-folded model around a non-planar point, we strive to always satisfy $\phi_{f_i}(x) = 0$ exactly. The common starting point of a flat surface is an interesting case, as it is a bifurcation point between surfaces satisfying \theoremref{Thm:supporting_plane} and those that do not, which also holds for its discretization \eqref{eq:folding_const_normalized}. To that end we solve our problem with an iterative SQP solver with a linesearch, added with two simple strategies to handle the folding constraints $\phi_{d_i}(\x)$:
\begin{enumerate}
	\item Use a penalty term (\cite{nocedal}) punishing on deviation from the constraints. \label{opt:penalty}
	\item Use linesearch method that does not except meshes deviating from the constraints $\phi_{d_i}(\x)$.
\end{enumerate}
As the functions involved in the constraints $\phi_{d_i}(\x)$ are not continuous, we replace them by the analytic approximations:

\begin{align} 
\begin{split}\label{eq:const_inner}
\tanh(hx) \approx \text{sgn}(x) \\
\frac{1+\tanh(hx)}{2} \approx H(x)\\
\end{split}
\end{align}
using a fix parameter $h=1000$.
\begin{equation}
\text{sgn}(x) \approx \tanh(kx)
\end{equation}
We refer to the approximated constraints as $\phi^*_i(\x)$.

Thus, we replace the optimzation problem \eqref{eq:const_opt} with the following problem:
\begin{equation} \label{eq:const_opt}
\begin{aligned}
& \argmin_x f(x) + \alpha \sum \phi^*_i(\x)^2 \\
& \textrm{subject to} \\
& \phi_{d_i}(\x) = 0, \ \  i = 1, \ldots, m. \\ 
\end{aligned}
\end{equation}
Where $\alpha$ is a metaparameter starting at $\alpha_0 = 1$ that doubles its value if the linesearch cannot find a point that both decreases a given merit function while satisfying the supporting planes conditions exactly. In practice, the penalty term only affects points that are very close to being planar points, while approaching zero very quickly around already folded points.
\subsection{Equality constrainted SQP}
\MiR{Write down the thing, but make sure to convexify stuff. Use the Jacobian and stuff from that paper, but note that its much better with hessian and lagrangian rather than laplacian, and also convexification is better, and get rid of the lbfgs in porjection. Especially better for higher resolution models.}

\MiR{
TODO: Explain here about what we do, flows similar to \cite{rabi2018shape}, just use lagrangian where the hessian is first convexified such that (called $H^*$) instead of the DOG Laplacian , which is basically SQP. Use the same strategy to minimally petrubate $J$ to $J^*$ as done in \cite{rabi2018shape}. Quickly go through the details such as merit functions (no need in the "projection" operator with lbfgs), and refer to the appendix for more technical things such as convexification of simple energies. 
At the end we write down our minimization as
\begin{equation} \label{eq:const_opt}
\begin{aligned}
& \argmin_x
& & f(x) \\
& \textrm{subject to}
& & g_i(x) = 0, \ \  i = 1, \ldots, m.
\end{aligned}
\end{equation}
}
By subsequently solving KKT systems of the form for a given mesh $x^k$, finding the step direction $d^{k+1}$:
\begin{equation} \label{eq:KKT_eps}
\begin{gathered}
{K} \begin{pmatrix} d^{k+1} \\ \lambda^{k+1} \end{pmatrix}=\mathbf{b} \\
{K}=\begin{pmatrix}
{H^*(x)+\sum\lambda_i^{k} \nabla g_i(x)} & {J^{*\tr}(x)}\\
{J^*(x)} &  0 \\
\end{pmatrix}, \ \ 
\mathbf{b}=\begin{pmatrix}
{\nabla f(x^k)} \\ 
\boldsymbol{-g(x^k)}\\
\end{pmatrix}.
\end{gathered}
\end{equation}
\MiR{
and use a linesearch with a merit function. Say that hard constraints are only dog + edge stitching as in \cite{rabi18} whereas other constraints throughout the paper are enforced by penalizing them, using a convex hessian approximation of gauss-newton (besides the length which are easy to convexify).
}

\subsection{Objectives and constraints} \label{sec:dog_obj}
\MiR{Gauss-newton hessian for constraint stuff. Convexification for others if needed (maybe write it down in appendix).}

\begin{figure} [h]
	\centering
	\includegraphics[width=\linewidth]{figures/fold_bias_compare}
	\caption{With and without bias. Same deformations. \MiR{todo caption.} }
	\label{fig:fold_bias_compare}
\end{figure}